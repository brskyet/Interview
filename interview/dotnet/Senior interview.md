[Хороший сайт для подготовки](https://backendinterview.ru/)

# Что такое CAP-теорема? Что означают буквы CAP?
CAP-теорема — это принцип, говорящий о том, что в распределенных системах можно достичь только двух из трех гарантий: согласованности (Consistency), доступности (Availability) и устойчивости к разделению (Partition tolerance).
-   Согласованность (C): Все узлы в системе видят одни и те же данные одновременно.
-   Доступность (A): Запросы к системе получают ответ (либо успешный, либо ошибочный) без задержек.
-   Устойчивость к разделению (P): Система продолжает функционировать, даже если часть узлов или сетевое соединение между ними недоступны.

###### Какие известные вам системы характеризуются как CA, CP или AP?
-   CA: Традиционные реляционные БД, такие как RDBMS.
-   CP: Например, HBase, ZooKeeper.
-   AP: Например, Cassandra, Couchbase.

Могут ли разработчики настроить систему так, чтобы менять гарантии в зависимости от ситуации?
Да, некоторые системы, такие как Cassandra, позволяют настраивать уровень согласованности на основе запроса.

###### Что такое "согласованность событийной выдачи" и как это связано с CAP-теоремой?
Это когда система обеспечивает согласованность на уровне отдельных операций или событий, а не в глобальном масштабе. Это связано с CAP-теоремой, так как может быть решением для систем, которые выбирают доступность перед строгой согласованностью.

###### Какие стратегии или подходы вы бы использовали для обеспечения устойчивости к разделению в распределенной системе?
Применение репликации данных, использование принципов идемпотентности и повторные попытки для операций, а также разработка системы с учетом возможности отказа отдельных компонентов.

# Гарантии доставки в брокерах сообщений
Гарантии доставки определяют уровень уверенности, с которым сообщение или данные будут доставлены получателю в распределенной системе.
-   "At most once": Сообщение доставляется не более одного раза. Возможна потеря сообщения.
-   "At least once": Гарантируется, что сообщение будет доставлено, но возможны дубликаты.
-   "Exactly once": Сообщение доставляется строго один раз.
Чтобы реализовать доставку строго один раз необходимо использовать механизм идемпотентности.
В RabbitMQ существуют варианты с доставкой как минимум раз и как максимум раз, строго один раз - надо реализовывать на стороне приложения. По умолчанию работает режим как минимум один раз, т.к. клиент должен сам подтвердить, что он получил сообщение, а если он по факту получил, но не подтвердил, то возможно дублирование.
В Kafka доступны все три режима.

# Идемпотентность
Идемпотентность - когда повторная обработка не меняет состояние системы. Достигается передачей уникального идентификатора запроса. В случае, если идентификатор повторяется, мы не обрабатываем запрос второй раз. В RabbitMQ по умолчанию передается идентификатор. Для web API можно реализовать свой, тогда даже если пользователь несколько раз нажал на кнопку, то мы не будем повторять обработку запроса.

# Шардирование
Шардирование — это разбиение большой базы данных на меньшие, более управляемые части или "шарды". Это делается для повышения производительности, масштабируемости и упрощения управления.
Преимущества: повышение производительности, масштабируемость, распределение нагрузки. Недостатки: сложность реализации, проблемы с транзакциями через шарды, возможные сложности с запросами на объединение.
Горизонтальное шардирование разбивает таблицу на строки, каждый шард содержит отдельный набор строк. Вертикальное разбивает таблицу на столбцы.
###### Основные методы шардирования
Range-based шардирование: данные распределяются по шардам на основе диапазонов значений (например, по дате).
Hash-based: использует хеш-функцию от ключа шарда для определения, в каком шарде будет храниться запись. Преимущества: равномерное распределение данных. Недостатки: сложности при изменении количества шардов.
Directory-based: использует отдельный сервис или таблицу, чтобы отслеживать, где хранятся данные.

Также существует географическое шардирование — это размещение данных на основе географического расположения, например, для ускорения доступа к данным для пользователей в определенном регионе.
  
Consistent hashing — это метод, который используется в распределенных системах для эффективного распределения данных по узлам, особенно актуальный для систем, где узлы могут добавляться или удаляться. В контексте шардирования баз данных этот метод позволяет минимизировать перераспределение данных при изменении количества шардов.
Ключи распределяются по образному кольцу с помощью хэш-функции.
[Почитать тут](https://backendinterview.ru/db/dBTheory/distrubedDb/sharding.html#%D0%9A%D0%BE%D0%BD%D1%81%D0%B8%D1%81%D1%82%D0%B5%D0%BD%D1%82%D0%BD%D1%8B%D0%B9-%D1%85%D1%8D%D1%88)
# Kafka vs RabbitMQ
###### RabbitMQ
-   Паблишеры (publishers) отправляют сообщения на exchange’и
-   Exchange’и отправляют сообщения в очереди и в другие exchange’и
-   RabbitMQ отправляет подтверждения паблишерам при получении сообщения
-   Получатели (consumers) поддерживают постоянные TCP-соединения с RabbitMQ и объявляют, какую очередь(-и) они получают
-   RabbitMQ проталкивает (push) сообщения получателям
-   Получатели отправляют подтверждения успеха/ошибки
-   После успешного получения, сообщения удаляются из очередей

###### Kafka
Понимание журнала (и топика) и партиций являются ключом к пониманию Kafka’и. Итак, чем партиционированный журнал отличается от набора очередей? Давайте представим, как это выглядит.
![[../../../attachments/Pasted image 20231026191748.png]]
Вместо того чтобы помещать сообщения в очередь FIFO и отслеживать статус этого сообщения в очереди, как это делает RabbitMQ, Kafka просто добавляет его в журнал, и на этом все.

Сообщение остается, вне зависимости от того, будет ли оно получено один или несколько раз. Удаляется оно в соответствии с политикой удерживания данных (retention policy, также называемый window time period). Каким же образом информация забирается из топика?

Каждый получатель отслеживает, где она находится в журнале: имеется указатель на последнее полученное сообщение и этот указатель называется адресом смещения. Получатели поддерживают этот адрес через клиентские библиотеки, и в зависимости от версии Kafka адрес сохраняется либо в ZooKeeper, либо в самой Kafka’е.

Отличительная особенность модели журналирования в том, что она мгновенно устраняет множество сложностей, касающихся состояния доставки сообщений и, что более важно для получателей, позволяет им перематывать назад, возвращаться и получать сообщения по предыдущему относительному адресу. Например, представьте, что вы разворачиваете сервис, который выставляет счета, учитывающие заказы, размещаемые клиентами. У службы случилась ошибка, и она неправильно рассчитывает все счета за 24 часа. С RabbitMQ в лучшем случае вам нужно будет как-то переопубликовать эти заказы только на сервисе счетов. Но с Kafka вы просто перемещаете относительный адрес для этого получателя на 24 часа назад.

Каждая партиция представляет собой отдельный файл, в котором гарантируется очередность сообщений. Это важно помнить: порядок сообщений гарантируется только в одной партиции. В дальнейшем это может привести к некоторому противоречию между потребностями в очередности сообщений и потребностями в производительности, поскольку производительность в Kafka также масштабируется партициями. Партиция не может поддерживать конкурирующих получателей, блок параллельности Kafka — это сама партиция. Поэтому, если нам нужны три получателя счетов, нам нужно как минимум три партиции(1 воркер на 1 партицию).

В Kafka соблюдается принцип «тупой брокер – умный потребитель». Таким образом, Kafka не отслеживает, какие записи считываются потребителем и после этого удаляются, а просто хранит их в течение заданного периода времени (например, суток), либо до тех пор, пока не будет достигнут некоторый порог. Потребители сами опрашивают Kafka, не появилось ли у него новых сообщений, и указывают, какие записи им нужно прочесть. Таким образом, они могут увеличивать или уменьшать смещение, переходя к нужной записи; при этом события могут переигрываться или повторно обрабатываться.
# EF Core
###### Кэш
Когда объекты загружаются в контекст Entity Framework через операции, такие как Find, Where или ToList, эти объекты автоматически кэшируются в контексте.
Если вы попытаетесь получить доступ к тем же данным в пределах этого контекста, EF будет использовать кэшированную версию этих объектов вместо выполнения нового запроса к базе данных.
Этот кэш существует только в пределах жизненного цикла конкретного экземпляра контекста. Когда контекст уничтожается или освобождается, кэш также уничтожается.
Из-за этого могут возникать проблемы, т.к. в некоторых случаях EF может брать неактуальные уже данные из кэша. Чтобы этого избежать - можно сбросить кэш методом Reload. Либо использовать DbContext с коротким временем жизни

###### Changes tracker
Это механизм, который позволяет EF Core отслеживать и фиксировать изменения, произошедшие с сущностями после их загрузки из базы данных. Есть пять основных состояний: Added, Modified, Deleted, Unchanged и Detached.
`AsNoTracking` указывает, что результаты запроса не должны быть отслеживаемыми. Это может улучшить производительность при чтении данных, когда изменение или сохранение данных не требуется. `AsTracking` делает результаты запроса отслеживаемыми (это поведение по умолчанию).

###### Каким образом оптимально сделать bulk insert через EF Core?
1. Выключить автоматическое отслеживание
2. Использовать ExecuteUpdate, ExecuteDelete для обновления или удаления пачкой
3. Использовать стороннюю либку **EFCore.BulkExtensions**
4. Использовать RawSQL
При дефолтном поведении EF чаще всего будет производить вставку каждого элемента по одному

###### DbContext
При регистрации в DI DbContextFactory регистрируется как Singleton, а DbContext - Scoped 

# Библиотеки, про которые спрашивали
[Fluent validation](https://docs.fluentvalidation.net/en/latest/) - библа для валидации через Fluent API
Hangfire - шедулер
Polly - реализация политик ретраев для HTTP запросов

# gRPC
gRPC — это открытый фреймворк для удаленного вызова процедур (RPC), который работает на основе HTTP/2 и Protocol Buffers. gRPC обычно более производителен чем REST API благодаря компактной бинарной сериализации Protocol Buffers, он поддерживает потоковую передачу данных, двунаправленную коммуникацию, предоставляет строгую типизацию и контракты для служб.
Protocol Buffers (protobuf) — это язык определения данных и система для сериализации структурированных данных. В gRPC он используется для определения сообщений и служб, а также для бинарной сериализации и десериализации данных.
gRPC поддерживает четыре типа API: униарный (одиночный запрос-ответ), серверный поток (одиночный запрос, множественный ответ), клиентский поток (множественный запрос, одиночный ответ) и двунаправленный поток (множественные запросы и ответы).
# Выбор между базами
Реляционные vs нереляционные
- у реляционных присутствует схема БД, что повышает нагрузку при добавлении и изменении записей т.к. надо проверять соответствие схеме. Также такой вариант труднее горизонтально масштабировать, т.к. проверка схемы БД зачастую потребуется на всех базах.
- в реляционных базах проще организовать транзакции, да и вообще не уверен, что в нереляционных есть транзакции в принципе

# Как добавить столбцы со значениями по умолчанию в большие таблицы и построить по ним индекс
Сначала нужно добавить новый столбец без значения по умолчанию. Потом постепенно, пачками по 10к строк обновлять в транзакциях значения полей. После этого установить значение по умолчанию для нового столбца.
При создании индекса таблица может залочиться на слишком большой промежуток времени. Если это так, то можно создать индекс без блокировок, например, используя опцию CONCURRENTLY в PostgreSQL. Правда, это займет несколько больше времени.
# Observability
[Три основных "столпа"](https://lumigo.io/microservices-monitoring/microservices-observability/):
- *логи*
- *метрики*. Отслеживаются с течением времени для измерения состояния и производительности системы
- *трассировка*. Отображение жизненного цикла запроса при прохождении сквозь систему, например, через несколько микросервисов.
Основные паттерны:
- *Distributed Tracing*. Записывается информация о вызовах служб, выполненных во время обработки запроса, показывая различные задействованные службы, как они взаимодействуют и сколько времени каждая служба тратит на обработку внешних запросов. При распределенной трассировке каждому внешнему запросу присваивается уникальный идентификатор и он отслеживается на центральном сервере, что позволяет визуализировать и анализировать запросы и связанные с ними потоки данных.
- *Health Check API*. Иногда бывает, что служба в целом работает, но не может отвечать на запросы. В таком случае экземпляр службы должен иметь возможность уведомлять инфраструктуру развертывания, может ли он обрабатывать запросы или нет.
- *Log Aggregation*. ELK то есть
- *Auditing*. Аудит означает, что действия каждого пользователя или учетной записи службы записываются в журнал аудита. Записи журнала аудита фиксируют личность пользователя, действия, предпринятые пользователем, и связанные бизнес-объекты. Журналы аудита обычно хранятся в таблицах базы данных. 
  В среде микросервисов существует несколько способов реализации аудита, включая, помимо прочего:
	- Добавление журнала аудита в бизнес-логику — каждый метод службы может создавать запись журнала аудита и сохранять ее в базе данных.
	- Использование event sourcing. 
- *Exception Tracking*. При возникновении исключений - они всегда должны логироваться и команда разработки должна получать уведомление об этом.
- *Application Metrics*. В сбор метрик может входить:
	- Инфраструктурный уровень: CPU, RAM, HDD
	- Уровень приложений: задержки при обработке запросов и кол-во запросов
	- Уровень клиента: например, время загрузки приложения

Метрики бывают:
- _counter_ (счетчик)
- _gauge_ (датчик), например, для температуры, процент загрузки CPU и т.д.
- _histogram_ (гистограмма), т.е. график

# Когда стоит ставить nginx перед Kestrel 
Во внутренней сетке nginx не нужен перед Kestrel. Однако nginx нужен для:
- Безопасности, т.к. у него есть инструменты для ограничения скорости и защиты от DDoS атак
- Балансировка нагрузки, т.е. распределение трафика между несколькими экземплярами Kestrel
- Обработка статического контента
- SSL/TLS проще конфигурировать в nginx
- Сжатие входящих и исходящих данных
- Кэширование ответов для уменьшения нагрузки
- Надежность. Если Kestrel упадет, то nginx продолжит работать и отдавать, например, страницу с ошибкой